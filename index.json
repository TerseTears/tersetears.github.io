[{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/tags/julia/","section":"Tags","summary":"","title":"julia"},{"content":"","date":null,"permalink":"/tags/jump/","section":"Tags","summary":"","title":"JuMP"},{"content":"","date":null,"permalink":"/","section":"Mohamad Ali Mohamadi","summary":"","title":"Mohamad Ali Mohamadi"},{"content":"","date":null,"permalink":"/categories/optimization/","section":"Categories","summary":"","title":"optimization"},{"content":"","date":null,"permalink":"/tags/optimization/","section":"Tags","summary":"","title":"Optimization"},{"content":"","date":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":null,"permalink":"/categories/programming/","section":"Categories","summary":"","title":"programming"},{"content":"Introduction #This is a short comparison of the mathematical optimization facilities of the Julia language, where I compare JuMP.jl, Optim.jl, and Optimization.jl libraries.\nusing JuMP using Optim using Optimization using OptimizationOptimJL using OptimizationNLopt using BenchmarkTools import Ipopt import NLopt # Booth function. The three frameworks require different specifications. booth(x1, x2) = (x1 + 2x2 - 7)^2 + (2x1 + x2 -5)^2 booth_vector(x) = (x[1] + 2x[2] - 7)^2 + (2x[1] + x[2] -5)^2 booth_parameters(x, p) = (x[1] + 2x[2] - 7)^2 + (2x[1] + x[2] -5)^2; JuMP.jl Implementation #model = Model() set_silent(model) @variable(model, x[1:2]) register(model, :booth, 2, booth; autodiff = true) @NLobjective(model, Min, booth(x[1], x[2])) Ipopt.jl #set_optimizer(model, Ipopt.Optimizer) @benchmark JuMP.optimize!($model) BenchmarkTools.Trial: 592 samples with 1 evaluation. Range (min … max): 7.671 ms … 14.631 ms ┊ GC (min … max): 0.00% … 0.00% Time (median): 7.947 ms ┊ GC (median): 0.00% Time (mean ± σ): 8.431 ms ± 1.074 ms ┊ GC (mean ± σ): 0.00% ± 0.00% ▃█▇▅▂▃▃▂▂ ▁▁ ▂ ██████████████▅██▆▆▁▆▅▆▆▅▆▆▅▆▇▅▆▁▆▄▅▄▅▄▆▆▄▄▄▅▁▅▄▁▅▁▁▄▁▁▄▁▄ ▇ 7.67 ms Histogram: log(frequency) by time 12.9 ms \u0026lt; Memory estimate: 20.06 KiB, allocs estimate: 442. Ipopt really is not a good substitute for the native Julia implementation of Optim.jl. Nevertheless, the same algorithms implemented by Optim.jl can be found in the NLopt.jl package as bindings to implementations in other languages.\nNLopt.jl #set_optimizer(model, NLopt.Optimizer) set_optimizer_attribute(model, \u0026#34;algorithm\u0026#34;, :LD_LBFGS) @benchmark JuMP.optimize!($model) BenchmarkTools.Trial: 9546 samples with 1 evaluation. Range (min … max): 463.448 μs … 17.432 ms ┊ GC (min … max): 0.00% … 77. 15% Time (median): 480.015 μs ┊ GC (median): 0.00% Time (mean ± σ): 510.563 μs ± 190.779 μs ┊ GC (mean ± σ): 0.28% ± 0. 79% ▅█▆▅▄▅▄▃▃▂▁▁ ▁▁▁▁▁▁ ▁ ██████████████████████▇▇▅▆▆▅▇▄▆▆▆▆▆▅▇▆▅▆▆▆▆▆▇▆▆▆▇▇▆▅▆▆▄▄▆▄▅▄▅ █ 463 μs Histogram: log(frequency) by time 862 μs \u0026lt; Memory estimate: 12.28 KiB, allocs estimate: 244. Optim.jl #@benchmark Optim.optimize($booth_vector, [0., 0.], LBFGS(); autodiff = :forward) BenchmarkTools.Trial: 10000 samples with 4 evaluations. Range (min … max): 7.130 μs … 2.177 ms ┊ GC (min … max): 0.00% … 99.13% Time (median): 7.604 μs ┊ GC (median): 0.00% Time (mean ± σ): 8.887 μs ± 42.817 μs ┊ GC (mean ± σ): 9.58% ± 1.98% ▃▆███▇▆▅▄▄▃▃▂▂▁▁▁▁▁ ▁▁ ▁▁▁▁▁▂▂▁▂▁▂▁▁▁ ▂ ▅████████████████████▇███████████████████████▆▇▆▆▅▄▅▄▅▅▅▂▅ █ 7.13 μs Histogram: log(frequency) by time 12.1 μs \u0026lt; Memory estimate: 8.53 KiB, allocs estimate: 132. There is an interesting pull request to implement an Optim.jl interface for JuMP here. It would be interesting to compare the benchmarks once Optim becomes accessible from JuMP. For now, the almost 100 times slower speed may be attributed to either slower implementation in NLopt or the huge overhead of JuMP modeling. Alternatively, we can use another wrapper over optimization libraries, the Optimization.jl library.\nOptimization.jl #optf = OptimizationFunction(booth_parameters, Optimization.AutoForwardDiff()) prob = OptimizationProblem(optf, [0., 0.]) @benchmark solve($prob, LBFGS()) BenchmarkTools.Trial: 10000 samples with 1 evaluation. Range (min … max): 16.511 μs … 8.585 ms ┊ GC (min … max): 0.00% … 99.2 1% Time (median): 17.989 μs ┊ GC (median): 0.00% Time (mean ± σ): 21.041 μs ± 120.161 μs ┊ GC (mean ± σ): 8.04% ± 1.4 1% ▇█▂ ▃▇███▆▄▃▄▅▅▄▃▄▄▄▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▁▂ ▃ 16.5 μs Histogram: frequency by time 35.7 μs \u0026lt; Memory estimate: 14.94 KiB, allocs estimate: 211. There is clearly an overhead to using Optimization.jl making it more than two times slower than using Optim.jl natively.\nNLopt #@benchmark solve($prob, NLopt.LD_LBFGS()) BenchmarkTools.Trial: 10000 samples with 1 evaluation. Range (min … max): 413.016 μs … 1.420 ms ┊ GC (min … max): 0.00% … 0.00 % Time (median): 431.895 μs ┊ GC (median): 0.00% Time (mean ± σ): 451.550 μs ± 48.815 μs ┊ GC (mean ± σ): 0.00% ± 0.00 % ▄█ ▁██▃▇▆▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁ ▂ 413 μs Histogram: frequency by time 633 μs \u0026lt; Memory estimate: 3.58 KiB, allocs estimate: 64. Comparing the result with JuMP, one can conclude that the overheads in JuMP and Optimization.jl seem to be on the same level. The poorer benchmark results can therefore be attributed to NLopt.jl or the packages it wraps.\nAnother great thing about Optimization.jl is that it interfaces with the ModelingToolkit.jl package pretty well as well.\nWhich Framework to Choose #It is true that the Optim.jl may not really be a framework per se. Nevertheless, its raw speed makes it a great choice for embedding it in analyses where optimization may be the bottleneck. Such as calling an optimization routine in a long loop or matching and estimation.\nOn the other hand, a framework such as Optimization.jl, despite the added overhead, provides great convenience especially in situations where the function to be optimized is subject to rapid changes (such as testing modeling approaches), allowing one to quickly switch between different optimization methods with easy syntax.\nPersonally, I think JuMP is best for a single optimization problem, perhaps large-scaled, with many underlying considerations, such as done in the PowerModels.jl package. It is just not as easy to prototype a model using JuMP because of the sort of global approach it takes to modeling (a single model that is to be modified using macros). I see the Optimization.jl package as the framework with the greatest flexibility whose syntax does not deviate greatly from Julia Base, despite remaining highly extensible.\n","date":"5 August 2022","permalink":"/posts/julia-opt-benchmarks/","section":"Posts","summary":"Introduction #This is a short comparison of the mathematical optimization facilities of the Julia language, where I compare JuMP.","title":"Short Comparison of Julia Optimization Frameworks"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/categories/data-science/","section":"Categories","summary":"","title":"data science"},{"content":"Introduction #In this second part of the \u0026ldquo;journey through tyecon\u0026rdquo; series, I want to showcase the package\u0026rsquo;s facilities in simplifying tasks common to the predictive modelling part of data analysis. I will be using the Food.com dataset as before.\nSetup and Data Import #library(tidyverse) library(tidyselect) library(magrittr) library(vroom) library(tyecon) library(rsample) library(yardstick) library(glmnet) library(earth) library(pls) knitr::opts_chunk$set(fig.path = \u0026#34;\u0026#34;) knitr::opts_chunk$set(dev = \u0026#39;svg\u0026#39;) theme_set(theme_light()) set.seed(123) recipes \u0026lt;- vroom(\u0026#34;~/Workspace/foodrecipes/RAW_recipes.csv\u0026#34;) interacts \u0026lt;- vroom(\u0026#34;~/Workspace/foodrecipes/RAW_interactions.csv\u0026#34;) Nutrition values, except for calories, are all percent of daily value, a daily quota filled by the amount of the percentage by the consumption of the specific food.\nnutrs \u0026lt;- recipes %-\u0026gt;% { ids \u0026lt;- id select(nutrition) mutate(nutrition = str_replace_all(nutrition, \u0026#34;[\\\\[\\\\]\\\\\u0026#39;]\u0026#34;, \u0026#34;\u0026#34;)) separate(nutrition, into = c( \u0026#34;calories\u0026#34;, \u0026#34;sat_fat\u0026#34;, \u0026#34;sugar\u0026#34;, \u0026#34;sodium\u0026#34;, \u0026#34;protein\u0026#34;, \u0026#34;tot_fat\u0026#34;, \u0026#34;carbs\u0026#34; ), sep = \u0026#34;, \u0026#34;, convert = TRUE ) # Center and scale too mutate(across(everything(), \\(col) scale(col)[, 1])) set_attr(\u0026#34;ids\u0026#34;, ids) } nutrs ## # A tibble: 231,637 × 7 ## calories sat_fat sugar sodium protein tot_fat carbs ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 -0.355 -0.464 -0.0891 -0.228 -0.559 -0.464 -0.141 ## 2 -0.253 -0.232 -0.105 -0.0996 -0.217 -0.108 -0.178 ## 3 -0.172 -0.181 -0.0654 0.135 0.0738 -0.189 -0.129 ## 4 -0.0890 -0.245 -0.0929 -0.213 -0.354 -0.383 0.0543 ## 5 -0.102 -0.451 0.316 -0.0542 -0.542 -0.464 0.152 ## 6 -0.264 -0.335 -0.0366 -0.206 -0.439 -0.260 -0.105 ## 7 -0.0784 0.217 -0.0966 -0.0466 -0.491 -0.220 -0.117 ## 8 0.534 0.603 0.367 1.86 1.05 0.411 0.250 ## 9 3.19 2.80 1.53 0.613 1.58 3.92 2.50 ## 10 1.85 1.59 1.11 0.582 0.467 2.69 1.50 ## # … with 231,627 more rows And splitting into training and validation:\nnutrs_train:nutrs_test %\u0026lt;-% (initial_split(nutrs) %\u0026gt;% { list(training(.), testing(.)) }) Predicting Protein from PDV #Of course, since this is an index, it should just work well.\nLinear model #lm_model \u0026lt;- lm(protein ~ ., data = nutrs_train) %$\u0026gt;% { model \u0026lt;- . summary(.) %$\u0026gt;% { coefs \u0026lt;- as_tibble(coefficients, rownames = \u0026#34;term\u0026#34;) stats \u0026lt;- tibble(r.squared, sigma, df = fstatistic[2], fstat = fstatistic[1]) } pred_metrics \u0026lt;- { pred_tibble \u0026lt;- tibble( truth = fitted.values(.) + residuals(.), estimate = fitted.values(.) ) map_dfr(c(rmse, rsq, rsq_trad, msd, mae), ~ .(pred_tibble, truth, estimate)) } } lm_model ## $model ## ## Call: ## lm(formula = protein ~ ., data = nutrs_train) ## ## Coefficients: ## (Intercept) calories sat_fat sugar sodium tot_fat carbs ## -0.0002895 7.3769225 -2.7190916 -0.1166868 0.0264789 0.0542644 -5.7393293 ## ## ## $coefs ## # A tibble: 7 × 5 ## term Estimate `Std. Error` `t value` `Pr(\u0026gt;|t|)` ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 (Intercept) -0.000290 0.000907 -0.319 7.50e- 1 ## 2 calories 7.38 0.00933 791. 0 ## 3 sat_fat -2.72 0.00412 -660. 0 ## 4 sugar -0.117 0.00520 -22.5 1.62e-111 ## 5 sodium 0.0265 0.000861 30.8 2.90e-207 ## 6 tot_fat 0.0543 0.00181 30.0 2.59e-197 ## 7 carbs -5.74 0.00987 -582. 0 ## ## $stats ## # A tibble: 1 × 4 ## r.squared sigma df fstat ## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 0.849 0.378 6 163409. ## ## $pred_metrics ## # A tibble: 5 × 3 ## .metric .estimator .estimate ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 rmse standard 3.78e- 1 ## 2 rsq standard 8.49e- 1 ## 3 rsq_trad standard 8.49e- 1 ## 4 msd standard 1.62e-18 ## 5 mae standard 1.24e- 1 Predictions on the test data:\nmap_dfr(c(rmse, rsq, rsq_trad, msd, mae), ~ .( tibble( truth = nutrs_test$calories, estimate = predict(lm_model$model, nutrs_test) ), truth, estimate )) ## # A tibble: 5 × 3 ## .metric .estimator .estimate ## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 rmse standard 0.717 ## 2 rsq standard 0.467 ## 3 rsq_trad standard -0.142 ## 4 msd standard -0.00258 ## 5 mae standard 0.338 Multiple models together #We first build the general interface function for our loop over models:\nlasso \u0026lt;- partial(glmnet, alpha = 1) ridge \u0026lt;- partial(glmnet, alpha = 0) # prefix with dot dot to avoid name collision regression \u0026lt;- convoke( list(formula, data), lasso( x = model.matrix(formula, data)[, -1], y = data[[all.vars(formula)[1]]] ), ridge( x = model.matrix(formula, data)[, -1], y = data[[all.vars(formula)[1]]] ), earth(formula, data), plsr(formula, data = data) ) regression ## convoke function ## interfaces: lasso(), ridge(), earth(), plsr() ## args: formula, data, interface = lasso, interface.args And also the predict function:\npred_vec \u0026lt;- function(x, newdata, formula, ...) UseMethod(\u0026#34;pred_vec\u0026#34;) pred_vec.elnet \u0026lt;- function(x, newdata, formula, ...) { predict(x, newx = model.matrix(formula, newdata)[, -1], ...)[, 1] } pred_vec.earth \u0026lt;- function(x, newdata, formula, ...) { predict(x, newdata = newdata, ...)[, 1] } pred_vec.mvr \u0026lt;- function(x, newdata, formula, ...) { retval \u0026lt;- predict(x, newdata = newdata, ...) retval[, , dim(retval)[[3]]] } pred_vec_regs \u0026lt;- conflate(pred_vec(x, newdata, formula)) pred_vec_regs ## conflate function for pred_vec ## args: x, newdata, formula, object.args And the main loop:\nmodels_preds \u0026lt;- control( { holdout \u0026lt;- assessment(fold$splits) model \u0026lt;- regression(protein ~ ., analysis(fold$splits), interface = interface, lasso.lambda = lambda, earth.degree = degree, plsr.ncomp = 6 ) holdout$.fit \u0026lt;- pred_vec_regs(model, holdout, protein ~ .) list(model = model, rmse = rmse(holdout, protein, .fit)[[\u0026#34;.estimate\u0026#34;]]) }, fold = transpose(vfold_cv(nutrs_train, 5)) ~ 1, interface = c(\u0026#34;lasso\u0026#34;, \u0026#34;earth\u0026#34;, \u0026#34;plsr\u0026#34;) ~ 2, lambda = c(0.1, 0.2) ~ 3, degree = c(1, 2) ~ 4, ncomp = c(5, 6) ~ 5, .refiner = ~ confine(., lambda = interface %in% c(\u0026#34;lasso\u0026#34;, \u0026#34;ridge\u0026#34;), degree = interface == \u0026#34;earth\u0026#34;, ncomp = interface == \u0026#34;plsr\u0026#34; ), .unnest_value = TRUE ) models_preds ## # A tibble: 30 × 7 ## fold interface lambda degree ncomp model rmse ## \u0026lt;list\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;list\u0026gt; \u0026lt;dbl\u0026gt; ## 1 \u0026lt;named list [2]\u0026gt; lasso 0.1 NA NA \u0026lt;elnet\u0026gt; 0.870 ## 2 \u0026lt;named list [2]\u0026gt; lasso 0.2 NA NA \u0026lt;elnet\u0026gt; 0.911 ## 3 \u0026lt;named list [2]\u0026gt; earth NA 1 NA \u0026lt;earth\u0026gt; 0.351 ## 4 \u0026lt;named list [2]\u0026gt; earth NA 2 NA \u0026lt;earth\u0026gt; 0.341 ## 5 \u0026lt;named list [2]\u0026gt; plsr NA NA 5 \u0026lt;mvr\u0026gt; 0.330 ## 6 \u0026lt;named list [2]\u0026gt; plsr NA NA 6 \u0026lt;mvr\u0026gt; 0.330 ## 7 \u0026lt;named list [2]\u0026gt; lasso 0.1 NA NA \u0026lt;elnet\u0026gt; 1.02 ## 8 \u0026lt;named list [2]\u0026gt; lasso 0.2 NA NA \u0026lt;elnet\u0026gt; 1.09 ## 9 \u0026lt;named list [2]\u0026gt; earth NA 1 NA \u0026lt;earth\u0026gt; 2.50 ## 10 \u0026lt;named list [2]\u0026gt; earth NA 2 NA \u0026lt;earth\u0026gt; 4.84 ## # … with 20 more rows Now we can choose the appropriate model by testing the data on the validation set:\nmodels_chosen \u0026lt;- group_by(models_preds, across(-c(fold, model, rmse))) %\u0026gt;% summarise(model = list(first(model)), rmse = mean(rmse), .groups = \u0026#34;drop\u0026#34;) models_chosen ## # A tibble: 6 × 6 ## interface lambda degree ncomp model rmse ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;list\u0026gt; \u0026lt;dbl\u0026gt; ## 1 earth NA 1 NA \u0026lt;earth\u0026gt; 0.827 ## 2 earth NA 2 NA \u0026lt;earth\u0026gt; 1.60 ## 3 lasso 0.1 NA NA \u0026lt;elnet\u0026gt; 0.868 ## 4 lasso 0.2 NA NA \u0026lt;elnet\u0026gt; 0.895 ## 5 plsr NA NA 5 \u0026lt;mvr\u0026gt; 0.394 ## 6 plsr NA NA 6 \u0026lt;mvr\u0026gt; 0.394 And the validation set:\nmutate(rowwise(models_chosen), valid_rmse = { valid_set \u0026lt;- nutrs_test valid_set$.fit \u0026lt;- pred_vec_regs(model, valid_set, protein ~ .) rmse(valid_set, protein, .fit)[[\u0026#34;.estimate\u0026#34;]] } ) ## # A tibble: 6 × 7 ## # Rowwise: ## interface lambda degree ncomp model rmse valid_rmse ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;list\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; ## 1 earth NA 1 NA \u0026lt;earth\u0026gt; 0.827 0.397 ## 2 earth NA 2 NA \u0026lt;earth\u0026gt; 1.60 0.335 ## 3 lasso 0.1 NA NA \u0026lt;elnet\u0026gt; 0.868 0.903 ## 4 lasso 0.2 NA NA \u0026lt;elnet\u0026gt; 0.895 0.944 ## 5 plsr NA NA 5 \u0026lt;mvr\u0026gt; 0.394 0.403 ## 6 plsr NA NA 6 \u0026lt;mvr\u0026gt; 0.394 0.403 ","date":"2 July 2022","permalink":"/posts/journey-through-tyecon/predict-nutrs/","section":"Posts","summary":"Introduction #In this second part of the \u0026ldquo;journey through tyecon\u0026rdquo; series, I want to showcase the package\u0026rsquo;s facilities in simplifying tasks common to the predictive modelling part of data analysis.","title":"Journey Through `tyecon`: Predictions on Recipe Nutritions"},{"content":"","date":null,"permalink":"/tags/r/","section":"Tags","summary":"","title":"R"},{"content":"","date":null,"permalink":"/tags/tyecon/","section":"Tags","summary":"","title":"tyecon"},{"content":"Introduction #I\u0026rsquo;ve been working on my R package, tyecon for some time now. I think it can be a useful tool in performing day to day data analysis tasks. The idea is very simple: More higher order macros. There\u0026rsquo;s no reason to focus on the handful of existing ones, like the magrittr pipes or the dplyr syntax. We have a language here that supports lazy evaluation and first class functions. This is all we need to make programming life easier.\nData analysis tasks are quite unique. And it\u0026rsquo;s not always clear what the best approach towards writing less code could be. Nevertheless, I think searching for such possibilities is a legitimate endeavour, hence tyecon.\nIn this first part of the \u0026ldquo;Journey through tyecon\u0026rdquo; series, I explore the tags found in the Food.com dataset. I forgo mentioning specifically when I\u0026rsquo;m using any tyecon functionality, but that should be obvious from the code.\nSetup and Data Import #library(tidyverse) library(tidyselect) library(magrittr) library(glue) library(vroom) library(rlang) library(tyecon) knitr::opts_chunk$set(fig.path = \u0026#34;\u0026#34;) knitr::opts_chunk$set(dev = \u0026#39;svg\u0026#39;) theme_set(theme_light()) set.seed(123) recipes \u0026lt;- vroom(\u0026#34;~/Workspace/foodrecipes/RAW_recipes.csv\u0026#34;) interacts \u0026lt;- vroom(\u0026#34;~/Workspace/foodrecipes/RAW_interactions.csv\u0026#34;) Tags #tags \u0026lt;- recipes %-\u0026gt;% { select(id, tags) mutate(tag = str_replace_all(tags, \u0026#34;[\\\\[\\\\]\\\\\u0026#39;]\u0026#34;, \u0026#34;\u0026#34;)) select(-tags) mutate(tag = ifelse(tag == \u0026#34;\u0026#34;, NA, tag)) separate_rows(tag, sep = \u0026#34;, \u0026#34;) # convert to conventional R names mutate(tag = make.names(tag)) } Number of tags density plot:\ntags %-\u0026gt;% { group_by(id) summarise(n_tags = n()) } %$% { quantprob \u0026lt;- 0.9 quant \u0026lt;- quantile(n_tags, quantprob) ggplot(., aes(n_tags)) + geom_density() + geom_vline(xintercept = quant) + annotate(\u0026#34;label\u0026#34;, quant, 0, label = glue(\u0026#34;Quantile probability {quantprob}:\\n {quant}\u0026#34;) ) + xlab(\u0026#34;Number of tags\u0026#34;) + ylab(\u0026#34;Density\u0026#34;) } Therefore, We would still need a lot of tags for basic exploration of our data. Let us first create the tag dummies for each submitted recipe:\ntags_dummies \u0026lt;- tags %-\u0026gt;% { add_count(tag) arrange(desc(n)) select(-n) mutate(tagged = 1) pivot_wider(names_from = tag, values_from = tagged, values_fill = 0) # keep id as metadata ids \u0026lt;- id select(-id) set_attr(\u0026#34;ids\u0026#34;, ids) } The columns of the above data frame are thus sorted in order of tag frequency.\nThe strategy is to identify how much of the data is covered by a list of tags, and to append the list with a new tag and recompute the coverage rate. Starting from highly popular tags quickly culminates in a coverage rate of 1, so we are instead interested in whether a less popular subset still covers all of our observations.\nConsequently, let\u0026rsquo;s assume a coverage rate of 1 for the first few tags and then compute the coverage rate from thereon:\ntags_coverage \u0026lt;- tags_dummies %-\u0026gt;% { start \u0026lt;- 11 coverage_name \u0026lt;- as.character(glue(\u0026#34;coverage_{start}\u0026#34;)) head_names \u0026lt;- names(.)[1:start - 1] extract(start:100) nrows \u0026lt;- nrow(.) accumulate(`+`) map_dfc(~ length(which(. != 0)) / nrows) pivot_longer(everything(), values_to = coverage_name) { bind_rows(tibble(name = head_names, \u0026#34;{coverage_name}\u0026#34; := 1), .) } } tail(tags_coverage) ## # A tibble: 6 × 2 ## name coverage_11 ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 winter 0.999 ## 2 served.cold 0.999 ## 3 fish 0.999 ## 4 italian 0.999 ## 5 high.protein 0.999 ## 6 snacks 0.999 Therefore, it seems the first 100 tags would be sufficient for the analysis.\nA Look at the 100 Most Popular Tags #tags %-\u0026gt;% { count(tag) arrange(desc(n)) head(100) mutate(buckets = desc(ntile(n, 4))) } %\u0026gt;% ggplot(aes(fct_reorder(fct_reorder(tag, tag, .desc = TRUE), n), n)) + coord_flip() + facet_wrap(vars(buckets), nrow = 1, scales = \u0026#34;free_y\u0026#34;) + geom_col() + geom_label(aes(label = n), hjust = \u0026#34;right\u0026#34;, nudge_y = 100000) + ggtitle(glue(\u0026#34;Top 100 tags (of total {n_distinct(tags$tag)})\u0026#34;)) + annotate(\u0026#34;segment\u0026#34;, y = nrow(tags_dummies), yend = nrow(tags_dummies), x = 0, xend = 20 ) + theme( axis.title.y = element_blank(), strip.text.x = element_blank() ) Feature Extraction from Tags #From the chart, we can identify some useful tags. Of course, tags that already cover a good proportion of the data are useless as they introduce little variation for identification. Each tag on its own is also useless because apart from the first few tags, each tag has very little coverage of the data. Rather, we are looking for complementary tags or subsets that give good coverage of the data. We can use exploratory factor analysis to identify such latent factors. Of course, we could use PCA as well. One could even argue that since each tag is a category, we need to use multiple correspondence analysis instead. But this is unnecessary, since our tags are simply one-hot encoded and therefore are just dummies that can be treated as continuous.\ntags_factors \u0026lt;- tags_dummies %-\u0026gt;% { extract(1:100) { factanal(~., 20, .) } status \u0026lt;- c(pval = PVAL[[1]], converged = converged) use_series(loadings) (\\(.) t(.[1:dim(.)[1], ])) as_tibble(rownames = \u0026#34;factor\u0026#34;) pivot_longer(!factor, \u0026#34;tag\u0026#34;) mutate( factor = str_replace(factor, \u0026#34;(Factor)(.*)\u0026#34;, \u0026#34;fct_\\\\2\u0026#34;), value = abs(value) ) group_by(factor) arrange(desc(value), .by_group = TRUE) slice_head(n = 10) set_attr(\u0026#34;status\u0026#34;, status) } tags_factors %@% \u0026#34;status\u0026#34; ## pval converged ## 0 1 ggplot(tags_factors, aes(tag, value)) + geom_col() + coord_flip() + facet_wrap(vars(factor), scales = \u0026#34;free\u0026#34;, nrow = 5) + ylab(\u0026#34;value in factor\u0026#34;) + ggtitle(\u0026#34;Grouping of tags into latent factors\u0026#34;) + theme( axis.text.x = element_blank(), strip.text.x = element_blank(), axis.title.y = element_blank() ) The next step in exploratory factor analysis is to name our factors and group our variables into said factors. I exclude ingredient tags as the recipes data has the complete set already. Same for time to prepare. I also add dish type and occasion which the factor analysis hasn\u0026rsquo;t picked up.\nThe goal below is to aggregate as much of the data into groups. First creating the names of the new variables:\ntags_keep \u0026lt;- set_names(names(tags_dummies)) %$\u0026gt;% { dietary \u0026lt;- dietary easy \u0026lt;- easy has_occasion \u0026lt;- occasion occasion \u0026lt;- list( dinner_party = dinner.party, holiday_event = holiday.event, weeknight = weeknight, picnic = picnic ) dish_type \u0026lt;- list( main_dish = c(main.dish, lunch, breakfast, brunch), desserts = c(desserts, appetizers, cakes, snacks), bread = breads, salad = salads, soup = soups.stews, beverage = beverages ) side_dish \u0026lt;- c( side.dishes, desserts, appetizers, cakes, snacks, breads, salads, soups.stews, beverages ) healthy \u0026lt;- str_subset(., \u0026#34;\\\\bhealthy\\\\b\u0026#34;) low_in_something \u0026lt;- str_subset(., \u0026#34;\\\\blow\\\\b\u0026#34;) high_in_something \u0026lt;- str_subset(., \u0026#34;\\\\bhigh\\\\b\u0026#34;) has_cuisine \u0026lt;- cuisine cuisine \u0026lt;- list( american = str_subset(., \u0026#34;\\\\bamerican\\\\b\u0026#34;), european = c(str_subset(., \u0026#34;\\\\beuropean\\\\b\u0026#34;), str_subset(., \u0026#34;\\\\bitalian\\\\b\u0026#34;)), asian = str_subset(., \u0026#34;\\\\basian\\\\b\u0026#34;) ) has_equipment \u0026lt;- c(equipment, oven, stove.top, small.appliance) oven \u0026lt;- oven stove \u0026lt;- stove.top small_appliance \u0026lt;- small.appliance has_num_servings \u0026lt;- c(number.of.servings, for.1.or.2, for.large.groups) serve_small \u0026lt;- for.1.or.2 serve_large \u0026lt;- for.large.groups season \u0026lt;- list( winter = winter, summer = summer, fall = fall, spring = spring, seasonal = seasonal ) has_taste \u0026lt;- c(taste.mood, sweet, savory, spicy) taste \u0026lt;- list(sweet = sweet, savory = savory, spicy = spicy) } recipes_tags \u0026lt;- transmute( tags_dummies, !!!map(flatten(tags_keep), ~ if_else(reduce(tags_dummies[.], `+`) \u0026gt; 0, 1, 0)) ) %\u0026gt;% mutate(id = tags_dummies %@% ids) %\u0026gt;% select(id, everything()) Now our recipe tags are finally ready.\nvroom_write(recipes_tags, \u0026#34;~/Workspace/foodrecipes/out/recipes_tags.csv\u0026#34;) ","date":"1 June 2022","permalink":"/posts/journey-through-tyecon/explore-tags/","section":"Posts","summary":"Introduction #I\u0026rsquo;ve been working on my R package, tyecon for some time now.","title":"Journey Through `tyecon`: Exploring Food.com Tags"},{"content":"Continuing Where We Left #This post shows how to translate the second page of the dplyr cheatsheet to DataFrames.jl and Julia commnads.\nusing RDatasets, RCall, DataFrames, StatsBase, Statistics R\u0026#34;library(tidyverse)\u0026#34;; Setting up the data using RCall #mpg = dataset(\u0026#34;ggplot2\u0026#34;, \u0026#34;mpg\u0026#34;); Vectorized Functions #lag, lead #julia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; mutate(mpg, leadyear = lead(year)) %\u0026gt;% select(year, leadyear) %\u0026gt;% tail \u0026#34;\u0026#34;\u0026#34; RObject{VecSxp} # A tibble: 6 x 2 year leadyear \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; 1 1999 2008 2 2008 2008 3 2008 1999 4 1999 1999 5 1999 2008 6 2008 NA In Julia:\njulia\u0026gt; transform(mpg, :Year =\u0026gt; (x-\u0026gt;vcat(x[2:end], missing)) =\u0026gt; :leadYear)[ :, [:Year, :leadYear]] |\u0026gt; x-\u0026gt;last(x, 10) 10×2 DataFrame Row │ Year leadYear │ Int32 Int32? ─────┼───────────────── 1 │ 1999 2008 2 │ 2008 2008 3 │ 2008 1999 4 │ 1999 1999 5 │ 1999 2008 6 │ 2008 2008 7 │ 2008 1999 8 │ 1999 1999 9 │ 1999 2008 10 │ 2008 missing Note that one needs to wrap the anonymous function inside parentheses to avoid mixing with the =\u0026gt; operator.\ncumall #This function returns always false from the first false value it sees. For example:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; x \u0026lt;- c(1, 3, 5, 9, 4, 3, 2, 2) cumall(x \u0026lt; 6) \u0026#34;\u0026#34;\u0026#34; RObject{LglSxp} [1] TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE This is just a commulative product for logical values:\njulia\u0026gt; x = [1, 3, 5, 9, 4, 3, 2, 2]; julia\u0026gt; cumprod(x .\u0026lt; 6)\u0026#39; 1×8 adjoint(::BitVector) with eltype Bool: 1 1 1 0 0 0 0 0 cumany #This one returns true from the first true it sees:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; cumany(x \u0026gt; 6) \u0026#34;\u0026#34;\u0026#34; RObject{LglSxp} [1] FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE It would be equivalent to a logical sum:\njulia\u0026gt; cumsum(x .\u0026gt; 6)\u0026#39; 1×8 adjoint(::Vector{Int64}) with eltype Int64: 0 0 0 1 1 1 1 1 cummax #This just takes binary comparisons between the present element and its previous element:\njulia\u0026gt; R\u0026#34;cummax(x)\u0026#34; RObject{RealSxp} [1] 1 3 5 9 9 9 9 9 It is easy with the more general function accumulate in Julia:\njulia\u0026gt; accumulate(max, x)\u0026#39; 1×8 adjoint(::Vector{Int64}) with eltype Int64: 1 3 5 9 9 9 9 9 One could have in fact used this function with the previous examples as well by writing the appropriate anonymous function. Other functions such as mean, max etc. follow the same rule.\nRank functions #julia\u0026gt; R\u0026#34;cume_dist(x)\u0026#34; RObject{RealSxp} [1] 0.125 0.625 0.875 1.000 0.750 0.625 0.375 0.375 It is just the values of the empirical cdf:\njulia\u0026gt; ecdf(x)(x)\u0026#39; 1×8 adjoint(::Vector{Float64}) with eltype Float64: 0.125 0.625 0.875 1.0 0.75 0.625 0.375 0.375 julia\u0026gt; R\u0026#34;dense_rank(x)\u0026#34; RObject{IntSxp} [1] 1 3 5 6 4 3 2 2 julia\u0026gt; denserank(x)\u0026#39; 1×8 adjoint(::Vector{Int64}) with eltype Int64: 1 3 5 6 4 3 2 2 julia\u0026gt; R\u0026#34;min_rank(x)\u0026#34; RObject{IntSxp} [1] 1 4 7 8 6 4 2 2 Julia equivalent is the competerank:\njulia\u0026gt; competerank(x)\u0026#39; 1×8 adjoint(::Vector{Int64}) with eltype Int64: 1 4 7 8 6 4 2 2 TODO The dplyr ntile function seems rather unstandard and so the results differ from Julia:\njulia\u0026gt; R\u0026#34;ntile(x, 3)\u0026#34; RObject{IntSxp} [1] 1 2 3 3 2 2 1 1 julia\u0026gt; searchsortedfirst.(Ref(nquantile(x,2)), x)\u0026#39; 1×8 adjoint(::Vector{Int64}) with eltype Int64: 1 2 3 3 3 2 2 2 As for percen_rank it is just a normalization to the 0-1 interval, hence requires subtracting 1 first:\njulia\u0026gt; R\u0026#34;percent_rank(x)\u0026#34; RObject{RealSxp} [1] 0.0000000 0.4285714 0.8571429 1.0000000 0.7142857 0.4285714 0.1428571 [8] 0.1428571 julia\u0026gt; ((competerank(x).-1)/(length(x)-1))\u0026#39; 1×8 adjoint(::Vector{Float64}) with eltype Float64: 0.0 0.428571 0.857143 1.0 0.714286 0.428571 0.142857 0.142857 As for row_number rank:\njulia\u0026gt; R\u0026#34;row_number(x)\u0026#34; RObject{IntSxp} [1] 1 4 7 8 6 5 2 3 julia\u0026gt; ordinalrank(x)\u0026#39; 1×8 adjoint(::Vector{Int64}) with eltype Int64: 1 4 7 8 6 5 2 3 between #Julia simply understands the between notion in a mathematical notation:\njulia\u0026gt; R\u0026#34;between(x, 3, 6)\u0026#34; RObject{LglSxp} [1] FALSE TRUE TRUE FALSE TRUE TRUE FALSE FALSE julia\u0026gt; (3 .\u0026lt;= x .\u0026lt;= 6)\u0026#39; 1×8 adjoint(::BitVector) with eltype Bool: 0 1 1 0 1 1 0 0 near #Use the approximate notation (or the isapprox function):\njulia\u0026gt; R\u0026#34;near(2, 1.9999999999)\u0026#34; RObject{LglSxp} [1] TRUE julia\u0026gt; 2 ≈ 1.9999999999 true case_when #Julia doesn\u0026rsquo;t have a syntax for cases yet. The shortest equivalent that comes to mind is as follows:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; case_when(x \u0026gt; 3 \u0026amp; x \u0026lt; 5 ~ \u0026#34;medium\u0026#34;, x \u0026lt;= 3 ~ \u0026#34;small\u0026#34;, x \u0026gt;= 5 ~ \u0026#34;large\u0026#34;, TRUE ~ \u0026#34;unknown\u0026#34;) \u0026#34;\u0026#34;\u0026#34; RObject{StrSxp} [1] \u0026#34;small\u0026#34; \u0026#34;small\u0026#34; \u0026#34;large\u0026#34; \u0026#34;large\u0026#34; \u0026#34;medium\u0026#34; \u0026#34;small\u0026#34; \u0026#34;small\u0026#34; \u0026#34;small\u0026#34; julia\u0026gt; map(x) do x_ if (3 \u0026lt; x_ \u0026lt; 5) \u0026#34;medium\u0026#34; elseif (x_ \u0026lt;= 3) \u0026#34;small\u0026#34; elseif (5 \u0026lt;= x_) \u0026#34;large\u0026#34; else \u0026#34;unknown\u0026#34; end end 8-element Vector{String}: \u0026#34;small\u0026#34; \u0026#34;small\u0026#34; \u0026#34;large\u0026#34; \u0026#34;large\u0026#34; \u0026#34;medium\u0026#34; \u0026#34;small\u0026#34; \u0026#34;small\u0026#34; \u0026#34;small\u0026#34; coalesce #Both functions are inspired by the SQL command and so work nearly identically:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; y \u0026lt;- c(NA, 2, 5, NA, 6) z \u0026lt;- c(3, 7, NA, 9, 4) coalesce(y,z) \u0026#34;\u0026#34;\u0026#34; RObject{RealSxp} [1] 3 2 5 9 6 julia\u0026gt; y = [missing, 2, 5, missing, 6]; julia\u0026gt; z = [3, 7, missing, 9, 4]; julia\u0026gt; coalesce.(y, z)\u0026#39; 1×5 adjoint(::Vector{Int64}) with eltype Int64: 3 2 5 9 6 It is important to note that vectorizing coalesce (i.e. the dot) is necessary. Otherwise, since the y vector isn\u0026rsquo;t missing, nothing happens.\nif_else #The julia equivalent is the vectorized ifelse:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; if_else(x \u0026gt; 3, \u0026#34;large\u0026#34;, \u0026#34;small\u0026#34;) \u0026#34;\u0026#34;\u0026#34; RObject{StrSxp} [1] \u0026#34;small\u0026#34; \u0026#34;small\u0026#34; \u0026#34;large\u0026#34; \u0026#34;large\u0026#34; \u0026#34;large\u0026#34; \u0026#34;small\u0026#34; \u0026#34;small\u0026#34; \u0026#34;small\u0026#34; julia\u0026gt; ifelse.(x .\u0026gt; 3, \u0026#34;large\u0026#34;, \u0026#34;small\u0026#34;) 8-element Vector{String}: \u0026#34;small\u0026#34; \u0026#34;small\u0026#34; \u0026#34;large\u0026#34; \u0026#34;large\u0026#34; \u0026#34;large\u0026#34; \u0026#34;small\u0026#34; \u0026#34;small\u0026#34; \u0026#34;small\u0026#34; na_if #Simply use the more general functions in Julia:\njulia\u0026gt; R\u0026#34;na_if(x, 9)\u0026#34; RObject{RealSxp} [1] 1 3 5 NA 4 3 2 2 julia\u0026gt; replace(x, 9=\u0026gt;missing)\u0026#39; 1×8 adjoint(::Vector{Union{Missing, Int64}}) with eltype Union{Missing, Int64}: 1 3 5 missing 4 3 2 2 pmax and pmin #julia\u0026gt; R\u0026#34;pmax(y,z)\u0026#34; RObject{RealSxp} [1] NA 7 NA NA 6 julia\u0026gt; max.(y,z)\u0026#39; 1×5 adjoint(::Vector{Union{Missing, Int64}}) with eltype Union{Missing, Int64}: missing 7 missing missing 6 recode #Again, simply using the more general function replace:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; cvec \u0026lt;- c(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;c\u0026#34;) recode(cvec, a = \u0026#34;apple\u0026#34;) \u0026#34;\u0026#34;\u0026#34; RObject{StrSxp} [1] \u0026#34;apple\u0026#34; \u0026#34;b\u0026#34; \u0026#34;apple\u0026#34; \u0026#34;c\u0026#34; \u0026#34;b\u0026#34; \u0026#34;apple\u0026#34; \u0026#34;c\u0026#34; julia\u0026gt; cvec = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;c\u0026#34;]; julia\u0026gt; replace(cvec, \u0026#34;a\u0026#34;=\u0026gt;\u0026#34;apple\u0026#34;) 7-element Vector{String}: \u0026#34;apple\u0026#34; \u0026#34;b\u0026#34; \u0026#34;apple\u0026#34; \u0026#34;c\u0026#34; \u0026#34;b\u0026#34; \u0026#34;apple\u0026#34; \u0026#34;c\u0026#34; Summary Functions #Back to dataframes where summary functions are better illustrated.\nn() #julia\u0026gt; R\u0026#34;mpg %\u0026gt;% group_by(cyl) %\u0026gt;% summarise(n=n())\u0026#34; RObject{VecSxp} # A tibble: 4 x 2 cyl n \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; 1 4 81 2 5 4 3 6 79 4 8 70 julia\u0026gt; groupby(mpg, :Cyl) |\u0026gt; x-\u0026gt;combine(x, nrow) 4×2 DataFrame Row │ Cyl nrow │ Int32 Int64 ─────┼────────────── 1 │ 4 81 2 │ 5 4 3 │ 6 79 4 │ 8 70 n_distinct #julia\u0026gt; R\u0026#34;mpg %\u0026gt;% group_by(cyl) %\u0026gt;% summarise(trans=n_distinct(trans))\u0026#34; RObject{VecSxp} # A tibble: 4 x 2 cyl trans \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; 1 4 9 2 5 2 3 6 8 4 8 8 julia\u0026gt; groupby(mpg, :Cyl) |\u0026gt; x-\u0026gt;combine(x, :Trans =\u0026gt; (x_-\u0026gt;length(unique(x_))) =\u0026gt; :Trans) 4×2 DataFrame Row │ Cyl Trans │ Int32 Int64 ─────┼────────────── 1 │ 4 9 2 │ 5 2 3 │ 6 8 4 │ 8 8 Alternatively, one could just composition the two inner functions instead (use \\circ to write the operator):\njulia\u0026gt; groupby(mpg, :Cyl) |\u0026gt; x-\u0026gt;combine(x, :Trans =\u0026gt; length ∘ unique =\u0026gt; :Trans) 4×2 DataFrame Row │ Cyl Trans │ Int32 Int64 ─────┼────────────── 1 │ 4 9 2 │ 5 2 3 │ 6 8 4 │ 8 8 mean and median #julia\u0026gt; R\u0026#34;mean(x)\u0026#34; RObject{RealSxp} [1] 3.625 julia\u0026gt; mean(x) 3.625 julia\u0026gt; R\u0026#34;median(x)\u0026#34; RObject{RealSxp} [1] 3 julia\u0026gt; median(x) 3.0 first, last, nth #The Julia equivalents are also named first and last. As for nth, one has to simply use array indexing.\nRank and Spread functions #These are all available in Julia by similar names:\njulia\u0026gt; R\u0026#34;c(max(x), min(x), quantile(x, 0.25), IQR(x), mad(x), sd(x), var(x))\u0026#34; RObject{RealSxp} 25% 9.000000 1.000000 2.000000 2.250000 1.482600 2.503569 6.267857 julia\u0026gt; [maximum(x); minimum(x); quantile(x, 0.25); iqr(x); mad(x); std(x); var(x)]\u0026#39; 1×7 adjoint(::Vector{Float64}) with eltype Float64: 9.0 1.0 2.0 2.25 1.4826 2.50357 6.26786 Row Names #Julia dataframes do not have row names by design so there is nothing to worry about here.\nCombining Tables #Combining tables is really easy in Julia and is similar to how it is done in R for the most part (since both are inspired by SQL verbs).\nColumn and row binding #Binding columns is done with the hcat function:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; df1 \u0026lt;- tibble(a = 1:3, b = 4:6) df2 \u0026lt;- tibble(c = 7:9, d = 10:12) bind_cols(df1, df2) \u0026#34;\u0026#34;\u0026#34; RObject{VecSxp} # A tibble: 3 x 4 a b c d \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; 1 1 4 7 10 2 2 5 8 11 3 3 6 9 12 julia\u0026gt; df1 = DataFrame(a=1:3, b=4:6); julia\u0026gt; df2 = DataFrame(c=7:9, d=10:12); julia\u0026gt; hcat(df1, df2) 3×4 DataFrame Row │ a b c d │ Int64 Int64 Int64 Int64 ─────┼──────────────────────────── 1 │ 1 4 7 10 2 │ 2 5 8 11 3 │ 3 6 9 12 Binding rows requires vcat:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; df1 \u0026lt;- tibble(a = 1:3, b = 4:6) df2 \u0026lt;- tibble(a = 7:9, b = 10:12) bind_rows(df1, df2) \u0026#34;\u0026#34;\u0026#34; RObject{VecSxp} # A tibble: 6 x 2 a b \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; 1 1 4 2 2 5 3 3 6 4 7 10 5 8 11 6 9 12 julia\u0026gt; df1 = DataFrame(a=1:3, b=4:6); julia\u0026gt; df2 = DataFrame(a=7:9, b=10:12); julia\u0026gt; vcat(df1, df2) 6×2 DataFrame Row │ a b │ Int64 Int64 ─────┼────────────── 1 │ 1 4 2 │ 2 5 3 │ 3 6 4 │ 7 10 5 │ 8 11 6 │ 9 12 Joins #Example data taken from DataFrames.jl:\njulia\u0026gt; df1 = DataFrame(City = [\u0026#34;Amsterdam\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;New York\u0026#34;, \u0026#34;New York\u0026#34;], Job = [\u0026#34;Lawyer\u0026#34;, \u0026#34;Lawyer\u0026#34;, \u0026#34;Lawyer\u0026#34;, \u0026#34;Doctor\u0026#34;, \u0026#34;Doctor\u0026#34;], Category = [1, 2, 3, 4, 5]); julia\u0026gt; df2 = DataFrame(Location = [\u0026#34;Amsterdam\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;New York\u0026#34;, \u0026#34;New York\u0026#34;], Work = [\u0026#34;Lawyer\u0026#34;, \u0026#34;Lawyer\u0026#34;, \u0026#34;Lawyer\u0026#34;, \u0026#34;Doctor\u0026#34;, \u0026#34;Doctor\u0026#34;], Name = [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;]); julia\u0026gt; innerjoin(df1, df2, on = [:City =\u0026gt; :Location, :Job =\u0026gt; :Work]) 9×4 DataFrame Row │ City Job Category Name │ String String Int64 String ─────┼───────────────────────────────────── 1 │ Amsterdam Lawyer 1 a 2 │ London Lawyer 2 b 3 │ London Lawyer 3 b 4 │ London Lawyer 2 c 5 │ London Lawyer 3 c 6 │ New York Doctor 4 d 7 │ New York Doctor 5 d 8 │ New York Doctor 4 e 9 │ New York Doctor 5 e In R, it would be:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; df1 \u0026lt;- tibble(City = c(\u0026#34;Amsterdam\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;New York\u0026#34;, \u0026#34;New York\u0026#34;), Job = c(\u0026#34;Lawyer\u0026#34;, \u0026#34;Lawyer\u0026#34;, \u0026#34;Lawyer\u0026#34;, \u0026#34;Doctor\u0026#34;, \u0026#34;Doctor\u0026#34;), Category = c(1, 2, 3, 4, 5)) df2 \u0026lt;- tibble(Location = c(\u0026#34;Amsterdam\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;London\u0026#34;, \u0026#34;New York\u0026#34;, \u0026#34;New York\u0026#34;), Work = c(\u0026#34;Lawyer\u0026#34;, \u0026#34;Lawyer\u0026#34;, \u0026#34;Lawyer\u0026#34;, \u0026#34;Doctor\u0026#34;, \u0026#34;Doctor\u0026#34;), Name = c(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;, \u0026#34;e\u0026#34;)) inner_join(df1, df2, by = c(\u0026#34;City\u0026#34; = \u0026#34;Location\u0026#34;, \u0026#34;Job\u0026#34; = \u0026#34;Work\u0026#34;)) \u0026#34;\u0026#34;\u0026#34; RObject{VecSxp} # A tibble: 9 x 4 City Job Category Name \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; 1 Amsterdam Lawyer 1 a 2 London Lawyer 2 b 3 London Lawyer 2 c 4 London Lawyer 3 b 5 London Lawyer 3 c 6 New York Doctor 4 d 7 New York Doctor 4 e 8 New York Doctor 5 d 9 New York Doctor 5 e Set operations in R are somewhat redunant in the presence of join verbs, and so in Julia one needs to rely soley on those join verbs.\nThis concludes the dplyr cheatsheet translation to DataFrames.jl commands.\n","date":"13 November 2021","permalink":"/posts/dplyr-dataframes-part2/","section":"Posts","summary":"Continuing Where We Left #This post shows how to translate the second page of the dplyr cheatsheet to DataFrames.","title":"dplyr Cheatsheet to DataFrames.jl Page 2"},{"content":"Introduction #With the release of v1.0 of the DataFrames.jl package, it would seem appropriate to introduce a rather comprehensive cheatsheet of it. One that is of special use to people who come from tidyverse (arguably, the best data transformation syntax there is for combined expressiveness and brevity).\nThe order of topics is the same as dplyr cheatsheet.\nusing RDatasets, RCall, DataFrames, StatsBase, InteractiveErrors R\u0026#34;library(dplyr)\u0026#34;; Setting up the data using RCall #data = dataset(\u0026#34;datasets\u0026#34;, \u0026#34;iris\u0026#34;) @rput data; Summarize Cases #summarize #julia\u0026gt; R\u0026#34;summarize(data, avSL = mean(SepalLength), avSW = mean(SepalWidth))\u0026#34; RObject{VecSxp} avSL avSW 1 5.843333 3.057333 In Julia:\njulia\u0026gt; combine(data, [:SepalLength, :SepalWidth] .=\u0026gt; mean .=\u0026gt; [:avSL, :avSW]) 1×2 DataFrame Row │ avSL avSW │ Float64 Float64 ─────┼────────────────── 1 │ 5.84333 3.05733 There are two important things to note. Firstly, broadcasting is mandatory. Secondly, the syntax allows for one factoring of the function in the middle.\nNow let us summarize by different functions:\njulia\u0026gt; combine(data, [:SepalLength, :SepalWidth] .=\u0026gt; [maximum, minimum] .=\u0026gt; [:maxSL, :minSW]) 1×2 DataFrame Row │ maxSL minSW │ Float64 Float64 ─────┼────────────────── 1 │ 7.9 2.0 And with anonymous functions:\njulia\u0026gt; combine(data, [:SepalLength, :SepalWidth] .=\u0026gt; [x-\u0026gt;sum(x./100), x-\u0026gt;sum(sqrt.(x))] .=\u0026gt; [:x1, :x2]) 1×2 DataFrame Row │ x1 x2 │ Float64 Float64 ─────┼────────────────── 1 │ 8.765 261.619 The r equivalent would be:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; summarize(data, x1=sum(SepalLength/100), x2=sum(sqrt(SepalWidth))) \u0026#34;\u0026#34;\u0026#34; RObject{VecSxp} x1 x2 1 8.765 261.6187 The reason that r is often-times nicer is quotation. With DataFrames.jl on the other hand, the idea is to simply pass the actual data and data identifiers around. This means greater flexibility but slightly more verbose syntax.\nFor instance, consider summarizing by matching column names:\njulia\u0026gt; combine(data, filter(x-\u0026gt;occursin.(\u0026#34;Sepal\u0026#34;, x), names(data)) .=\u0026gt; mean) 1×2 DataFrame Row │ SepalLength_mean SepalWidth_mean │ Float64 Float64 ─────┼─────────────────────────────────── 1 │ 5.84333 3.05733 In R, one needs to explicitly use other function to escape the quoting procedure:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; summarize(data, across(contains(\u0026#34;Sepal\u0026#34;), mean)) \u0026#34;\u0026#34;\u0026#34; RObject{VecSxp} SepalLength SepalWidth 1 5.843333 3.057333 Both have their ups and downs. Basically, the field of nonstandard evaluation will require its own functions, whereas, by avoiding that, one can rely on existing functions or at least only slightly modified functions (based on multiple dispatch for instance) to arrive at the desired results.\ncount #data = dataset(\u0026#34;ggplot2\u0026#34;, \u0026#34;mpg\u0026#34;) @rput data; #julia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; data \u0026lt;- as_tibble(data) count(data, Cyl, Drv) \u0026#34;\u0026#34;\u0026#34; RObject{VecSxp} # A tibble: 9 x 3 Cyl Drv n \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; 1 4 4 23 2 4 f 58 3 5 f 4 4 6 4 32 5 6 f 43 6 6 r 4 7 8 4 48 8 8 f 1 9 8 r 21 Any function that operates on (sub)dataframes can be used immediately (nrow here):\njulia\u0026gt; combine(groupby(data, [:Cyl, :Drv], sort = true), nrow) 9×3 DataFrame Row │ Cyl Drv nrow │ Int32 Cat… Int64 ─────┼──────────────────── 1 │ 4 4 23 2 │ 4 f 58 3 │ 5 f 4 4 │ 6 4 32 5 │ 6 f 43 6 │ 6 r 4 7 │ 8 4 48 8 │ 8 f 1 9 │ 8 r 21 This was a proper interlude to the next topic, grouping.\nGroup Cases #Ungroup #The general grouping operation in DataFrames.jl is as above, whereby a \u0026ldquo;sub\u0026rdquo; dataframe is recognized, perhaps not overly different from views in arrays.\nUngrouping is done rather automatically. The default value of ungroup in the transformation functions is true.\njulia\u0026gt; df = groupby(data, [:Cyl, :Drv], sort = true) GroupedDataFrame with 9 groups based on keys: Cyl, Drv First Group (23 rows): Cyl = 4, Drv = CategoricalArrays.CategoricalValue{String, UInt8} \u0026#34;4\u0026#34; Row │ Manufacturer Model Displ Year Cyl Trans D ⋯ │ Categorical… Categorical… Float64 Int32 Int32 Categorical… C ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ audi a4 quattro 1.8 1999 4 manual(m5) 4 ⋯ 2 │ audi a4 quattro 1.8 1999 4 auto(l5) 4 3 │ audi a4 quattro 2.0 2008 4 manual(m6) 4 4 │ audi a4 quattro 2.0 2008 4 auto(s6) 4 5 │ subaru forester awd 2.5 1999 4 manual(m5) 4 ⋯ 6 │ subaru forester awd 2.5 1999 4 auto(l4) 4 7 │ subaru forester awd 2.5 2008 4 manual(m5) 4 8 │ subaru forester awd 2.5 2008 4 manual(m5) 4 ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ 16 │ subaru impreza awd 2.5 2008 4 auto(s4) 4 ⋯ 17 │ subaru impreza awd 2.5 2008 4 manual(m5) 4 18 │ subaru impreza awd 2.5 2008 4 manual(m5) 4 19 │ toyota 4runner 4wd 2.7 1999 4 manual(m5) 4 20 │ toyota 4runner 4wd 2.7 1999 4 auto(l4) 4 ⋯ 21 │ toyota toyota tacoma 4wd 2.7 1999 4 manual(m5) 4 22 │ toyota toyota tacoma 4wd 2.7 1999 4 auto(l4) 4 23 │ toyota toyota tacoma 4wd 2.7 2008 4 manual(m5) 4 5 columns and 7 rows omitted ⋮ Last Group (21 rows): Cyl = 8, Drv = CategoricalArrays.CategoricalValue{String, UInt8} \u0026#34;r\u0026#34; Row │ Manufacturer Model Displ Year Cyl Trans ⋯ │ Categorical… Categorical… Float64 Int32 Int32 Categorical… ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ chevrolet c1500 suburban 2wd 5.3 2008 8 auto(l4) ⋯ 2 │ chevrolet c1500 suburban 2wd 5.3 2008 8 auto(l4) 3 │ chevrolet c1500 suburban 2wd 5.3 2008 8 auto(l4) 4 │ chevrolet c1500 suburban 2wd 5.7 1999 8 auto(l4) 5 │ chevrolet c1500 suburban 2wd 6.0 2008 8 auto(l4) ⋯ 6 │ chevrolet corvette 5.7 1999 8 manual(m6) 7 │ chevrolet corvette 5.7 1999 8 auto(l4) 8 │ chevrolet corvette 6.2 2008 8 manual(m6) ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ 14 │ ford mustang 4.6 1999 8 auto(l4) ⋯ 15 │ ford mustang 4.6 1999 8 manual(m5) 16 │ ford mustang 4.6 2008 8 manual(m5) 17 │ ford mustang 4.6 2008 8 auto(l5) 18 │ ford mustang 5.4 2008 8 manual(m6) ⋯ 19 │ lincoln navigator 2wd 5.4 1999 8 auto(l4) 20 │ lincoln navigator 2wd 5.4 1999 8 auto(l4) 21 │ lincoln navigator 2wd 5.4 2008 8 auto(l6) 5 columns and 5 rows omitted julia\u0026gt; df2 = combine(df, :) 234×11 DataFrame Row │ Cyl Drv Manufacturer Model Displ Year Trans ⋯ │ Int32 Cat… Cat… Cat… Float64 Int32 Cat… ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ 4 4 audi a4 quattro 1.8 1999 manual(m5) ⋯ 2 │ 4 4 audi a4 quattro 1.8 1999 auto(l5) 3 │ 4 4 audi a4 quattro 2.0 2008 manual(m6) 4 │ 4 4 audi a4 quattro 2.0 2008 auto(s6) 5 │ 4 4 subaru forester awd 2.5 1999 manual(m5) ⋯ 6 │ 4 4 subaru forester awd 2.5 1999 auto(l4) 7 │ 4 4 subaru forester awd 2.5 2008 manual(m5) 8 │ 4 4 subaru forester awd 2.5 2008 manual(m5) ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ 228 │ 8 r ford mustang 4.6 1999 manual(m5) ⋯ 229 │ 8 r ford mustang 4.6 2008 manual(m5) 230 │ 8 r ford mustang 4.6 2008 auto(l5) 231 │ 8 r ford mustang 5.4 2008 manual(m6) 232 │ 8 r lincoln navigator 2wd 5.4 1999 auto(l4) ⋯ 233 │ 8 r lincoln navigator 2wd 5.4 1999 auto(l4) 234 │ 8 r lincoln navigator 2wd 5.4 2008 auto(l6) 4 columns and 219 rows omitted The colon indicates that all items should be retained (whether columns or rows, depending on the specific argument it is used in place of). Here, it means to keep all rows and columns. However, since combine does ungrouping by default, that means retaining the original content of the data:\njulia\u0026gt; nrow(df2) == nrow(data) true It is important to note, however, that presently, grouping changes the row order.\njulia\u0026gt; df3 = combine(data, :) 234×11 DataFrame Row │ Manufacturer Model Displ Year Cyl Trans Drv ⋯ │ Categorical… Categorical… Float64 Int32 Int32 Categorical… Catego ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ audi a4 1.8 1999 4 auto(l5) f ⋯ 2 │ audi a4 1.8 1999 4 manual(m5) f 3 │ audi a4 2.0 2008 4 manual(m6) f 4 │ audi a4 2.0 2008 4 auto(av) f 5 │ audi a4 2.8 1999 6 auto(l5) f ⋯ 6 │ audi a4 2.8 1999 6 manual(m5) f 7 │ audi a4 3.1 2008 6 auto(av) f 8 │ audi a4 quattro 1.8 1999 4 manual(m5) 4 ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ 228 │ volkswagen passat 1.8 1999 4 manual(m5) f ⋯ 229 │ volkswagen passat 1.8 1999 4 auto(l5) f 230 │ volkswagen passat 2.0 2008 4 auto(s6) f 231 │ volkswagen passat 2.0 2008 4 manual(m6) f 232 │ volkswagen passat 2.8 1999 6 auto(l5) f ⋯ 233 │ volkswagen passat 2.8 1999 6 manual(m5) f 234 │ volkswagen passat 3.6 2008 6 auto(s6) f 5 columns and 219 rows omitted julia\u0026gt; df3 == data true whereas:\njulia\u0026gt; df2 == data false In r, use of the ungroup function is needed.\nRow-wise operation #Row-wise is, conceptually, setting each row as its own group. Nevertheless, oftentimes we do not need to think this way.\nSay you want to know the minimum between 1.5 times the city miles per gallon and highway miles per galon for each model. In r, it would require this:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; data %\u0026gt;% rowwise() %\u0026gt;% mutate(maxy = max(1.5*Cty, Hwy)) %\u0026gt;% select(maxy, everything()) \u0026#34;\u0026#34;\u0026#34; RObject{VecSxp} # A tibble: 234 x 12 # Rowwise: maxy Manufacturer Model Displ Year Cyl Trans Drv Cty Hwy Fl \u0026lt;dbl\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; 1 29 audi a4 1.8 1999 4 auto(l… f 18 29 p 2 31.5 audi a4 1.8 1999 4 manual… f 21 29 p 3 31 audi a4 2 2008 4 manual… f 20 31 p 4 31.5 audi a4 2 2008 4 auto(a… f 21 30 p 5 26 audi a4 2.8 1999 6 auto(l… f 16 26 p 6 27 audi a4 2.8 1999 6 manual… f 18 26 p 7 27 audi a4 3.1 2008 6 auto(a… f 18 27 p 8 27 audi a4 quat… 1.8 1999 4 manual… 4 18 26 p 9 25 audi a4 quat… 1.8 1999 4 auto(l… 4 16 25 p 10 30 audi a4 quat… 2 2008 4 manual… 4 20 28 p # … with 224 more rows, and 1 more variable: Class \u0026lt;fct\u0026gt; In Julia, it is simply a matter of specifying the operation itself to rowwise:\njulia\u0026gt; transform(data, [:Cty, :Hwy] =\u0026gt; ByRow((x,y)-\u0026gt;max(1.5*x,y)) =\u0026gt; :maxy) |\u0026gt; x-\u0026gt;x[:, Cols([:maxy], :)] 234×12 DataFrame Row │ maxy Manufacturer Model Displ Year Cyl Trans ⋯ │ Float64 Categorical… Categorical… Float64 Int32 Int32 Categorical ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ 29.0 audi a4 1.8 1999 4 auto(l5) ⋯ 2 │ 31.5 audi a4 1.8 1999 4 manual(m5) 3 │ 31.0 audi a4 2.0 2008 4 manual(m6) 4 │ 31.5 audi a4 2.0 2008 4 auto(av) 5 │ 26.0 audi a4 2.8 1999 6 auto(l5) ⋯ 6 │ 27.0 audi a4 2.8 1999 6 manual(m5) 7 │ 27.0 audi a4 3.1 2008 6 auto(av) 8 │ 27.0 audi a4 quattro 1.8 1999 4 manual(m5) ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ 228 │ 31.5 volkswagen passat 1.8 1999 4 manual(m5) ⋯ 229 │ 29.0 volkswagen passat 1.8 1999 4 auto(l5) 230 │ 28.5 volkswagen passat 2.0 2008 4 auto(s6) 231 │ 31.5 volkswagen passat 2.0 2008 4 manual(m6) 232 │ 26.0 volkswagen passat 2.8 1999 6 auto(l5) ⋯ 233 │ 27.0 volkswagen passat 2.8 1999 6 manual(m5) 234 │ 26.0 volkswagen passat 3.6 2008 6 auto(s6) 6 columns and 219 rows omitted Manipulate Cases #Filter #Filtering essentially uses the same principles as applied to any other Julia data structure, and can even use the conventional filter function for this purpose:\njulia\u0026gt; filter(:Cty =\u0026gt; x-\u0026gt;(x\u0026gt;20), data)[:, Cols(:Cty,:)] 45×11 DataFrame Row │ Cty Manufacturer Model Displ Year Cyl Trans ⋯ │ Int32 Categorical… Categorical… Float64 Int32 Int32 Categorical… ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ 21 audi a4 1.8 1999 4 manual(m5) ⋯ 2 │ 21 audi a4 2.0 2008 4 auto(av) 3 │ 22 chevrolet malibu 2.4 2008 4 auto(l4) 4 │ 28 honda civic 1.6 1999 4 manual(m5) 5 │ 24 honda civic 1.6 1999 4 auto(l4) ⋯ 6 │ 25 honda civic 1.6 1999 4 manual(m5) 7 │ 23 honda civic 1.6 1999 4 manual(m5) 8 │ 24 honda civic 1.6 1999 4 auto(l4) ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ 39 │ 21 volkswagen jetta 2.5 2008 5 auto(s6) ⋯ 40 │ 21 volkswagen jetta 2.5 2008 5 manual(m5) 41 │ 35 volkswagen new beetle 1.9 1999 4 manual(m5) 42 │ 29 volkswagen new beetle 1.9 1999 4 auto(l4) 43 │ 21 volkswagen new beetle 2.0 1999 4 manual(m5) ⋯ 44 │ 21 volkswagen passat 1.8 1999 4 manual(m5) 45 │ 21 volkswagen passat 2.0 2008 4 manual(m6) 4 columns and 30 rows omitted Julia data collection functions usually take a function as the first argument in order to facilitate the use of do blocks. This doesn\u0026rsquo;t look nice when using piping. Therefore, my suggestion is to stick with the subset function. Besides, apparently, filter doesn\u0026rsquo;t work on data groups.\njulia\u0026gt; subset(data, :Cty =\u0026gt; x-\u0026gt;(x.\u0026gt;20))[:, Cols(:Cty,:)] 45×11 DataFrame Row │ Cty Manufacturer Model Displ Year Cyl Trans ⋯ │ Int32 Categorical… Categorical… Float64 Int32 Int32 Categorical… ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ 21 audi a4 1.8 1999 4 manual(m5) ⋯ 2 │ 21 audi a4 2.0 2008 4 auto(av) 3 │ 22 chevrolet malibu 2.4 2008 4 auto(l4) 4 │ 28 honda civic 1.6 1999 4 manual(m5) 5 │ 24 honda civic 1.6 1999 4 auto(l4) ⋯ 6 │ 25 honda civic 1.6 1999 4 manual(m5) 7 │ 23 honda civic 1.6 1999 4 manual(m5) 8 │ 24 honda civic 1.6 1999 4 auto(l4) ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ 39 │ 21 volkswagen jetta 2.5 2008 5 auto(s6) ⋯ 40 │ 21 volkswagen jetta 2.5 2008 5 manual(m5) 41 │ 35 volkswagen new beetle 1.9 1999 4 manual(m5) 42 │ 29 volkswagen new beetle 1.9 1999 4 auto(l4) 43 │ 21 volkswagen new beetle 2.0 1999 4 manual(m5) ⋯ 44 │ 21 volkswagen passat 1.8 1999 4 manual(m5) 45 │ 21 volkswagen passat 2.0 2008 4 manual(m6) 4 columns and 30 rows omitted Distinct #julia\u0026gt; unique(data, [:Cyl, :Drv]) 9×11 DataFrame Row │ Manufacturer Model Displ Year Cyl Trans ⋯ │ Categorical… Categorical… Float64 Int32 Int32 Categorical… ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ audi a4 1.8 1999 4 auto(l5) ⋯ 2 │ audi a4 2.8 1999 6 auto(l5) 3 │ audi a4 quattro 1.8 1999 4 manual(m5) 4 │ audi a4 quattro 2.8 1999 6 auto(l5) 5 │ audi a6 quattro 4.2 2008 8 auto(s6) ⋯ 6 │ chevrolet c1500 suburban 2wd 5.3 2008 8 auto(l4) 7 │ ford mustang 3.8 1999 6 manual(m5) 8 │ pontiac grand prix 5.3 2008 8 auto(s4) 9 │ volkswagen jetta 2.5 2008 5 auto(s6) ⋯ 5 columns omitted julia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; distinct(data, Cyl, Drv) \u0026#34;\u0026#34;\u0026#34; RObject{VecSxp} # A tibble: 9 x 2 Cyl Drv \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; 1 4 f 2 6 f 3 4 4 4 6 4 5 8 4 6 8 r 7 6 r 8 8 f 9 5 f Slice #The point of a function such as slice is to be used in pipes really. Otherwise one can simply do this:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; data[4:10,] \u0026#34;\u0026#34;\u0026#34; RObject{VecSxp} # A tibble: 7 x 11 Manufacturer Model Displ Year Cyl Trans Drv Cty Hwy Fl Class \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; 1 audi a4 2 2008 4 auto(a… f 21 30 p compa… 2 audi a4 2.8 1999 6 auto(l… f 16 26 p compa… 3 audi a4 2.8 1999 6 manual… f 18 26 p compa… 4 audi a4 3.1 2008 6 auto(a… f 18 27 p compa… 5 audi a4 quat… 1.8 1999 4 manual… 4 18 26 p compa… 6 audi a4 quat… 1.8 1999 4 auto(l… 4 16 25 p compa… 7 audi a4 quat… 2 2008 4 manual… 4 20 28 p compa… Same with julia:\njulia\u0026gt; data[4:10,:] 7×11 DataFrame Row │ Manufacturer Model Displ Year Cyl Trans Drv ⋯ │ Categorical… Categorical… Float64 Int32 Int32 Categorical… Catego ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ audi a4 2.0 2008 4 auto(av) f ⋯ 2 │ audi a4 2.8 1999 6 auto(l5) f 3 │ audi a4 2.8 1999 6 manual(m5) f 4 │ audi a4 3.1 2008 6 auto(av) f 5 │ audi a4 quattro 1.8 1999 4 manual(m5) 4 ⋯ 6 │ audi a4 quattro 1.8 1999 4 auto(l5) 4 7 │ audi a4 quattro 2.0 2008 4 manual(m6) 4 5 columns omitted Slice-sample #The StatsBase module can be used here.\njulia\u0026gt; data[rand(1:nrow(data), 10),:] 10×11 DataFrame Row │ Manufacturer Model Displ Year Cyl Trans D ⋯ │ Categorical… Categorical… Float64 Int32 Int32 Categorical… C ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ ford explorer 4wd 4.0 1999 6 auto(l5) 4 ⋯ 2 │ nissan altima 2.4 1999 4 auto(l4) f 3 │ volkswagen new beetle 1.9 1999 4 manual(m5) f 4 │ hyundai tiburon 2.7 2008 6 manual(m5) f 5 │ toyota toyota tacoma 4wd 2.7 1999 4 manual(m5) 4 ⋯ 6 │ chevrolet corvette 6.2 2008 8 manual(m6) r 7 │ hyundai sonata 3.3 2008 6 auto(l5) f 8 │ dodge durango 4wd 5.9 1999 8 auto(l4) 4 9 │ ford f150 pickup 4wd 4.6 1999 8 manual(m5) 4 ⋯ 10 │ volkswagen new beetle 2.5 2008 5 auto(s6) f 5 columns omitted Slice min and max #This is just a convenience function:\njulia\u0026gt; data[data.Cty .\u0026gt;= quantile(data.Cty, 0.75),:] 76×11 DataFrame Row │ Manufacturer Model Displ Year Cyl Trans Drv ⋯ │ Categorical… Categorical… Float64 Int32 Int32 Categorical… Catego ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ audi a4 1.8 1999 4 manual(m5) f ⋯ 2 │ audi a4 2.0 2008 4 manual(m6) f 3 │ audi a4 2.0 2008 4 auto(av) f 4 │ audi a4 quattro 2.0 2008 4 manual(m6) 4 5 │ audi a4 quattro 2.0 2008 4 auto(s6) 4 ⋯ 6 │ chevrolet malibu 2.4 1999 4 auto(l4) f 7 │ chevrolet malibu 2.4 2008 4 auto(l4) f 8 │ honda civic 1.6 1999 4 manual(m5) f ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ 70 │ volkswagen new beetle 2.0 1999 4 manual(m5) f ⋯ 71 │ volkswagen new beetle 2.0 1999 4 auto(l4) f 72 │ volkswagen new beetle 2.5 2008 5 manual(m5) f 73 │ volkswagen new beetle 2.5 2008 5 auto(s6) f 74 │ volkswagen passat 1.8 1999 4 manual(m5) f ⋯ 75 │ volkswagen passat 2.0 2008 4 auto(s6) f 76 │ volkswagen passat 2.0 2008 4 manual(m6) f 5 columns and 61 rows omitted The R code:\njulia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; slice_max(data, Cty, prop = 0.25) \u0026#34;\u0026#34;\u0026#34; RObject{VecSxp} # A tibble: 76 x 11 Manufacturer Model Displ Year Cyl Trans Drv Cty Hwy Fl Class \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; 1 volkswagen new be… 1.9 1999 4 manual… f 35 44 d subco… 2 volkswagen jetta 1.9 1999 4 manual… f 33 44 d compa… 3 volkswagen new be… 1.9 1999 4 auto(l… f 29 41 d subco… 4 honda civic 1.6 1999 4 manual… f 28 33 r subco… 5 toyota corolla 1.8 2008 4 manual… f 28 37 r compa… 6 honda civic 1.8 2008 4 manual… f 26 34 r subco… 7 toyota corolla 1.8 1999 4 manual… f 26 35 r compa… 8 toyota corolla 1.8 2008 4 auto(l… f 26 35 r compa… 9 honda civic 1.6 1999 4 manual… f 25 32 r subco… 10 honda civic 1.8 2008 4 auto(l… f 25 36 r subco… # … with 66 more rows Slice head and tail #again, mostly meaningful for pipes. Nevertheless:\njulia\u0026gt; data[end-5:end,:] 6×11 DataFrame Row │ Manufacturer Model Displ Year Cyl Trans Drv ⋯ │ Categorical… Categorical… Float64 Int32 Int32 Categorical… Catego ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ volkswagen passat 1.8 1999 4 auto(l5) f ⋯ 2 │ volkswagen passat 2.0 2008 4 auto(s6) f 3 │ volkswagen passat 2.0 2008 4 manual(m6) f 4 │ volkswagen passat 2.8 1999 6 auto(l5) f 5 │ volkswagen passat 2.8 1999 6 manual(m5) f ⋯ 6 │ volkswagen passat 3.6 2008 6 auto(s6) f 5 columns omitted Arrange #Instead of arrange, sort is used. The syntax is very clear:\njulia\u0026gt; sort(data, [order(:Year, rev=true), :Displ]) 234×11 DataFrame Row │ Manufacturer Model Displ Year Cyl Trans ⋯ │ Categorical… Categorical… Float64 Int32 Int32 Categorical… ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ honda civic 1.8 2008 4 manual(m5) ⋯ 2 │ honda civic 1.8 2008 4 auto(l5) 3 │ honda civic 1.8 2008 4 auto(l5) 4 │ toyota corolla 1.8 2008 4 manual(m5) 5 │ toyota corolla 1.8 2008 4 auto(l4) ⋯ 6 │ audi a4 2.0 2008 4 manual(m6) 7 │ audi a4 2.0 2008 4 auto(av) 8 │ audi a4 quattro 2.0 2008 4 manual(m6) ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ 228 │ chevrolet c1500 suburban 2wd 5.7 1999 8 auto(l4) ⋯ 229 │ chevrolet corvette 5.7 1999 8 manual(m6) 230 │ chevrolet corvette 5.7 1999 8 auto(l4) 231 │ chevrolet k1500 tahoe 4wd 5.7 1999 8 auto(l4) 232 │ dodge durango 4wd 5.9 1999 8 auto(l4) ⋯ 233 │ dodge ram 1500 pickup 4wd 5.9 1999 8 auto(l4) 234 │ chevrolet k1500 tahoe 4wd 6.5 1999 8 auto(l4) 5 columns and 219 rows omitted julia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; arrange(data, desc(Year), Displ) \u0026#34;\u0026#34;\u0026#34; RObject{VecSxp} # A tibble: 234 x 11 Manufacturer Model Displ Year Cyl Trans Drv Cty Hwy Fl Class \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; 1 honda civic 1.8 2008 4 manual… f 26 34 r subco… 2 honda civic 1.8 2008 4 auto(l… f 25 36 r subco… 3 honda civic 1.8 2008 4 auto(l… f 24 36 c subco… 4 toyota corolla 1.8 2008 4 manual… f 28 37 r compa… 5 toyota corolla 1.8 2008 4 auto(l… f 26 35 r compa… 6 audi a4 2 2008 4 manual… f 20 31 p compa… 7 audi a4 2 2008 4 auto(a… f 21 30 p compa… 8 audi a4 qua… 2 2008 4 manual… 4 20 28 p compa… 9 audi a4 qua… 2 2008 4 auto(s… 4 19 27 p compa… 10 honda civic 2 2008 4 manual… f 21 29 p subco… # … with 224 more rows One can in fact use any kind of sorting. See the sorting section in DataFrames.jl.\nAdding row at position #Again, this is just a convenience function. Let\u0026rsquo;s add a duplicate row for instance:\njulia\u0026gt; vcat(data, DataFrame(data[5,:])) 235×11 DataFrame Row │ Manufacturer Model Displ Year Cyl Trans Drv ⋯ │ Categorical… Categorical… Float64 Int32 Int32 Categorical… Catego ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ audi a4 1.8 1999 4 auto(l5) f ⋯ 2 │ audi a4 1.8 1999 4 manual(m5) f 3 │ audi a4 2.0 2008 4 manual(m6) f 4 │ audi a4 2.0 2008 4 auto(av) f 5 │ audi a4 2.8 1999 6 auto(l5) f ⋯ 6 │ audi a4 2.8 1999 6 manual(m5) f 7 │ audi a4 3.1 2008 6 auto(av) f 8 │ audi a4 quattro 1.8 1999 4 manual(m5) 4 ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ 229 │ volkswagen passat 1.8 1999 4 auto(l5) f ⋯ 230 │ volkswagen passat 2.0 2008 4 auto(s6) f 231 │ volkswagen passat 2.0 2008 4 manual(m6) f 232 │ volkswagen passat 2.8 1999 6 auto(l5) f 233 │ volkswagen passat 2.8 1999 6 manual(m5) f ⋯ 234 │ volkswagen passat 3.6 2008 6 auto(s6) f 235 │ audi a4 2.8 1999 6 auto(l5) f 5 columns and 220 rows omitted The issue is that specifying the position at which to insert the row can take extra work. See also append! and push! with the catch being modification of the original dataframe.\nExtract variables #Conventional indexing can be used:\npull #One can just use the fact that the dataframe is a collection of vectors in a dictionary-like relation:\njulia\u0026gt; data.Hwy 234-element Vector{Int32}: 29 29 31 30 26 26 27 26 25 28 ⋮ 28 29 29 29 28 29 26 26 26 julia\u0026gt; R\u0026#34;pull(data, Hwy)\u0026#34; RObject{IntSxp} [1] 29 29 31 30 26 26 27 26 25 28 27 25 25 25 25 24 25 23 20 15 20 17 17 26 23 [26] 26 25 24 19 14 15 17 27 30 26 29 26 24 24 22 22 24 24 17 22 21 23 23 19 18 [51] 17 17 19 19 12 17 15 17 17 12 17 16 18 15 16 12 17 17 16 12 15 16 17 15 17 [76] 17 18 17 19 17 19 19 17 17 17 16 16 17 15 17 26 25 26 24 21 22 23 22 20 33 [101] 32 32 29 32 34 36 36 29 26 27 30 31 26 26 28 26 29 28 27 24 24 24 22 19 20 [126] 17 12 19 18 14 15 18 18 15 17 16 18 17 19 19 17 29 27 31 32 27 26 26 25 25 [151] 17 17 20 18 26 26 27 28 25 25 24 27 25 26 23 26 26 26 26 25 27 25 27 20 20 [176] 19 17 20 17 29 27 31 31 26 26 28 27 29 31 31 26 26 27 30 33 35 37 35 15 18 [201] 20 20 22 17 19 18 20 29 26 29 29 24 44 29 26 29 29 29 29 23 24 44 41 29 26 [226] 28 29 29 29 28 29 26 26 26 select #julia\u0026gt; data[:, [:Hwy, :Cty]] 234×2 DataFrame Row │ Hwy Cty │ Int32 Int32 ─────┼────────────── 1 │ 29 18 2 │ 29 21 3 │ 31 20 4 │ 30 21 5 │ 26 16 6 │ 26 18 7 │ 27 18 8 │ 26 18 ⋮ │ ⋮ ⋮ 228 │ 29 21 229 │ 29 18 230 │ 28 19 231 │ 29 21 232 │ 26 16 233 │ 26 18 234 │ 26 17 219 rows omitted Note that when selecting only a single column, it is no different than the dot syntax and the return structure is not dataframe:\njulia\u0026gt; data[:, :Hwy] 234-element Vector{Int32}: 29 29 31 30 26 26 27 26 25 28 ⋮ 28 29 29 29 28 29 26 26 26 Of course, wrapping in vector the column symbol gives the desired result:\njulia\u0026gt; data[:, [:Hwy]] 234×1 DataFrame Row │ Hwy │ Int32 ─────┼─────── 1 │ 29 2 │ 29 3 │ 31 4 │ 30 5 │ 26 6 │ 26 7 │ 27 8 │ 26 ⋮ │ ⋮ 228 │ 29 229 │ 29 230 │ 28 231 │ 29 232 │ 26 233 │ 26 234 │ 26 219 rows omitted relocate #Just use Cols as before. For instance, to put columns starting with m at front:\njulia\u0026gt; data[:, Cols(filter(x-\u0026gt;occursin(r\u0026#34;^[mM].*\u0026#34;, x), names(data)), :Year, :Class, :)] 234×11 DataFrame Row │ Manufacturer Model Year Class Displ Cyl Trans ⋯ │ Categorical… Categorical… Int32 Categorical… Float64 Int32 Catego ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ audi a4 1999 compact 1.8 4 auto(l ⋯ 2 │ audi a4 1999 compact 1.8 4 manual 3 │ audi a4 2008 compact 2.0 4 manual 4 │ audi a4 2008 compact 2.0 4 auto(a 5 │ audi a4 1999 compact 2.8 6 auto(l ⋯ 6 │ audi a4 1999 compact 2.8 6 manual 7 │ audi a4 2008 compact 3.1 6 auto(a 8 │ audi a4 quattro 1999 compact 1.8 4 manual ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ 228 │ volkswagen passat 1999 midsize 1.8 4 manual ⋯ 229 │ volkswagen passat 1999 midsize 1.8 4 auto(l 230 │ volkswagen passat 2008 midsize 2.0 4 auto(s 231 │ volkswagen passat 2008 midsize 2.0 4 manual 232 │ volkswagen passat 1999 midsize 2.8 6 auto(l ⋯ 233 │ volkswagen passat 1999 midsize 2.8 6 manual 234 │ volkswagen passat 2008 midsize 3.6 6 auto(s 5 columns and 219 rows omitted To put Model after Year:\njulia\u0026gt; data[:, Cols( setdiff(propertynames(data), [:Model]) |\u0026gt; x-\u0026gt;insert!(x, findfirst(x .== :Year) + 1, :Model))] 234×11 DataFrame Row │ Manufacturer Displ Year Model Cyl Trans Drv ⋯ │ Categorical… Float64 Int32 Categorical… Int32 Categorical… Catego ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ audi 1.8 1999 a4 4 auto(l5) f ⋯ 2 │ audi 1.8 1999 a4 4 manual(m5) f 3 │ audi 2.0 2008 a4 4 manual(m6) f 4 │ audi 2.0 2008 a4 4 auto(av) f 5 │ audi 2.8 1999 a4 6 auto(l5) f ⋯ 6 │ audi 2.8 1999 a4 6 manual(m5) f 7 │ audi 3.1 2008 a4 6 auto(av) f 8 │ audi 1.8 1999 a4 quattro 4 manual(m5) 4 ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ 228 │ volkswagen 1.8 1999 passat 4 manual(m5) f ⋯ 229 │ volkswagen 1.8 1999 passat 4 auto(l5) f 230 │ volkswagen 2.0 2008 passat 4 auto(s6) f 231 │ volkswagen 2.0 2008 passat 4 manual(m6) f 232 │ volkswagen 2.8 1999 passat 6 auto(l5) f ⋯ 233 │ volkswagen 2.8 1999 passat 6 manual(m5) f 234 │ volkswagen 3.6 2008 passat 6 auto(s6) f 5 columns and 219 rows omitted julia\u0026gt; R\u0026#34;\u0026#34;\u0026#34; relocate(data, Model, .after = Year) \u0026#34;\u0026#34;\u0026#34; RObject{VecSxp} # A tibble: 234 x 11 Manufacturer Displ Year Model Cyl Trans Drv Cty Hwy Fl Class \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;int\u0026gt; \u0026lt;int\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;fct\u0026gt; 1 audi 1.8 1999 a4 4 auto(l… f 18 29 p comp… 2 audi 1.8 1999 a4 4 manual… f 21 29 p comp… 3 audi 2 2008 a4 4 manual… f 20 31 p comp… 4 audi 2 2008 a4 4 auto(a… f 21 30 p comp… 5 audi 2.8 1999 a4 6 auto(l… f 16 26 p comp… 6 audi 2.8 1999 a4 6 manual… f 18 26 p comp… 7 audi 3.1 2008 a4 6 auto(a… f 18 27 p comp… 8 audi 1.8 1999 a4 quat… 4 manual… 4 18 26 p comp… 9 audi 1.8 1999 a4 quat… 4 auto(l… 4 16 25 p comp… 10 audi 2 2008 a4 quat… 4 manual… 4 20 28 p comp… # … with 224 more rows Currently, there aren\u0026rsquo;t any helper functions for selection, though the general procedure isn\u0026rsquo;t that verbose in base Julia either.\nAcross function #As mentioned in the beginning, Julia provides quite flexible ways of combining data, and there is no need for extra across functions, mainly due to the employment of the broadcasting concept.\nMaking new variables #mutate, and transmutate #The mutate equivalent is transform. The select function is the transmutate equivalent, which only selects the specifided columns, and after applying the specified functions, returns only said columns.\nrename #julia\u0026gt; rename(data, [:Model, :Year] .=\u0026gt; [:type, :date]) 234×11 DataFrame Row │ Manufacturer type Displ date Cyl Trans Drv ⋯ │ Categorical… Categorical… Float64 Int32 Int32 Categorical… Catego ⋯ ─────┼────────────────────────────────────────────────────────────────────────── 1 │ audi a4 1.8 1999 4 auto(l5) f ⋯ 2 │ audi a4 1.8 1999 4 manual(m5) f 3 │ audi a4 2.0 2008 4 manual(m6) f 4 │ audi a4 2.0 2008 4 auto(av) f 5 │ audi a4 2.8 1999 6 auto(l5) f ⋯ 6 │ audi a4 2.8 1999 6 manual(m5) f 7 │ audi a4 3.1 2008 6 auto(av) f 8 │ audi a4 quattro 1.8 1999 4 manual(m5) 4 ⋮ │ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋮ ⋱ 228 │ volkswagen passat 1.8 1999 4 manual(m5) f ⋯ 229 │ volkswagen passat 1.8 1999 4 auto(l5) f 230 │ volkswagen passat 2.0 2008 4 auto(s6) f 231 │ volkswagen passat 2.0 2008 4 manual(m6) f 232 │ volkswagen passat 2.8 1999 6 auto(l5) f ⋯ 233 │ volkswagen passat 2.8 1999 6 manual(m5) f 234 │ volkswagen passat 3.6 2008 6 auto(s6) f 5 columns and 219 rows omitted This concludes the first page of the cheatsheet.\n","date":"2 November 2021","permalink":"/posts/dplyr-dataframes/","section":"Posts","summary":"Introduction #With the release of v1.","title":"dplyr Cheatsheet to DataFrames.jl Page 1"},{"content":"Simple Iterations #The goal is to solve the below expression iteratively for f(x):\n$$ f(x) = β\\left(f(x)+x\\right) $$\nOf course, we know what the answer is already, for comparison:\nβ = 0.8 f(x) = 1/(1-β)*β*x x = 0.1:0.1:10; The original way #Using a while loop can be ugly, since there isn\u0026rsquo;t a do-while syntax in Julia. One needs to specify a true case first and check convergence later:\nfcomp, iter = let v_ = zeros(length(x)), i = 0 while true v = β*(v_+x) i=i+1 maximum(abs.(v-v_)) \u0026lt; 1e-6 \u0026amp;\u0026amp; break v_ = v end (v_,i) end [f.(x) fcomp] 100×2 Matrix{Float64}: 0.4 0.4 0.8 0.8 1.2 1.2 1.6 1.6 2.0 2.0 2.4 2.4 2.8 2.8 3.2 3.2 3.6 3.6 4.0 4.0 ⋮ 36.8 36.8 37.2 37.2 37.6 37.6 38.0 38.0 38.4 38.4 38.8 38.8 39.2 39.2 39.6 39.6 40.0 40.0 iter 73 Without while loop #As a solution, we can adopt a more functional approach to the recursive problem. Below code is more clear on what it\u0026rsquo;s supposed to do, with the default case mentioned first, and what needs to be done otherwise, later. As for initialization, the function takes care of this task itself in the last line:\nfunction viterate(x, v0) viterate(v, v_, iter) = maximum(abs.(v-v_)) \u0026lt; 1e-6 ? (v, iter) : let v_ = v, v = β*(v_+x) viterate(v, v_, iter+1) end viterate(β*(v0+x), v0, 1) end fcomp2, iter2 = viterate(x, zeros(length(x))) [f.(x) fcomp2] 100×2 Matrix{Float64}: 0.4 0.4 0.8 0.8 1.2 1.2 1.6 1.6 2.0 2.0 2.4 2.4 2.8 2.8 3.2 3.2 3.6 3.6 4.0 4.0 ⋮ 36.8 36.8 37.2 37.2 37.6 37.6 38.0 38.0 38.4 38.4 38.8 38.8 39.2 39.2 39.6 39.6 40.0 40.0 iter2 73 ","date":"10 July 2021","permalink":"/posts/while-loops/","section":"Posts","summary":"Simple Iterations #The goal is to solve the below expression iteratively for f(x):","title":"Julia Frustrations and Fixes Part III: Do-While Loops"},{"content":"Main Issue #Variables kept from previous runs of a script can be the culprit behind all sorts of bugs when developing from the REPL. Consider this simple case:\nSimple example #Let\u0026rsquo;s say I define y somewhere in the code:\ny = 50 50 Now I define another function that really is supposed to just sum two values, but I forgot to also change the name of the second variable in the function call:\nfunction mysum(x,z) x + y end mysum(5,6) 55 If at this point, I would have been able to unset the value of y, I would have immediately gotten an error from the compiler.\nNow, imagine how REPL (read interactive) development works. That value definition is somewhere at the top of the script. Between the function definition and that value assignment are likely many edited lines. The function itself is quite likely much more complex than a simple sum, and the result, due to lines preceding the function definition, are not always constant. It might even be impossible to notice this bug without restarting Julia in the first place. And restarting Julia, well, is going to mean recompiling all those loaded packages. All in all, not a very REPL-development-friendly situation.\nFix for Julia \u0026lt;= 1.6 #It might be that a solution to this problem will be eventually (re)implemented in Julia. For now, this is how I deal with it:\nThe command names(Main) lists all the values used in the current REPL environment:\nnames(Main) 12-element Vector{Symbol}: Symbol(\u0026#34;@unassign\u0026#34;) :Base :Core :InteractiveUtils :Main :ans :clearvars :d :mysum :p :q :y The Main module always has the first four elements plus an additional ans element that is produced as the return value of any operation that is carried in the REPL. Even in a REPL environment where no other commands have yet been executed, executing the above command alone produces this value. I rarely reference ans so for my purposes, keeping only the first four elements of Main is a complete cleaning of the environment.\np = 50 q = 50 d = 50; To remove assigned variable value, a bit of metaprogrammming is necessary, since we\u0026rsquo;d need the left hand side of the assignment as well.\nmacro unassign(variables...) unassigns = map(x-\u0026gt;:($(esc(x)) = nothing), variables) quote $(unassigns...) end end @unassign p q (p,q) (nothing, nothing) To remove all variables from the environment, it is sufficient to notice that the first four elements of Main are constant. Moreover, other constant elements of the module (such as macros and functions symbols) cannot be reassigned in Julia. In other words, we can only un-assign variables for non-constant Julia symbols, hence the setdiff part.\nfunction clearvars() unassignexprs = quote $(map(x-\u0026gt;:($(x) = nothing), setdiff(names(Main), names(Main)[isconst.(Ref(Main), names(Main))]))...) end @eval $(unassignexprs) end clearvars() (d,y) (nothing, nothing) ","date":"9 July 2021","permalink":"/posts/clear-variables/","section":"Posts","summary":"Main Issue #Variables kept from previous runs of a script can be the culprit behind all sorts of bugs when developing from the REPL.","title":"Julia Frustrations and Fixes Part II: Clearing Variables"},{"content":"Main issue #An issue with the REPL workflow is that When sending a script (or any chunks) to the REPL, lines that produce error simply output that error and the REPL simply continues to execute the following lines. This can be quite problematic since we may not know why something isn\u0026rsquo;t working. Consider this example:\nError output #y = 5 y = y^x # ERROR: UndefVarError: x not defined ERROR: UndefVarError: x not defined map(x-\u0026gt;x, 1:100) 100-element Vector{Int64}: 1 2 3 4 5 6 7 8 9 10 ⋮ 92 93 94 95 96 97 98 99 100 z = y 5 Interactive errors #The way to solve this issue is to use the InteractiveErrors package, which halts the REPL until further action is taken:\nusing InteractiveErrors y = y^x # REPL halts at above, waiting for user input ERROR: UndefVarError: x not defined # ... # once input is received, it continues z = y; ","date":"7 July 2021","permalink":"/posts/repl-errors/","section":"Posts","summary":"Main issue #An issue with the REPL workflow is that When sending a script (or any chunks) to the REPL, lines that produce error simply output that error and the REPL simply continues to execute the following lines.","title":"Julia Frustrations and Fixes Part I: REPL Errors"},{"content":"Frustrations and Fixes for Julia Series # Cumbersome globals, bug-inducing as well (Ricatti solver issue) Terrible pipe operator weird choice of having map take function first then data, even though map is a data function itself. This causes issues with the pipe operator idea as well. Column-major vs row-major Need good internet for adding packages (can\u0026rsquo;t use it effectively when outside of town) Poor but understandable reshaping of vectors of vectors into matrices (especially for multidimensional arrays) Unnamed vectors, no annotations possible returning multiple values from map in consistent way. No pattern matching (data diffusion, exit condition for value comp only using if) Using yaml as Data Source: Challenges #","date":"1 January 0001","permalink":"/posts/upcoming/","section":"Posts","summary":"Frustrations and Fixes for Julia Series # Cumbersome globals, bug-inducing as well (Ricatti solver issue) Terrible pipe operator weird choice of having map take function first then data, even though map is a data function itself.","title":"Upcoming Blog Posts"}]